{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1f32c32",
   "metadata": {},
   "source": [
    "### Encode Categorical Features:\n",
    "- Categorical encoding is converting categorical variables (textual or nominal data) into numerical format that machine learning algorithms can use. Common methods include:\n",
    "\n",
    "- ``Label Encoding:`` Assigning each unique category an integer label. Suitable for ordinal categories or tree-based models.\n",
    "\n",
    "- ``One-Hot Encoding:`` Creating binary columns for each category, indicating presence/absence. Good for nominal categorical variables with no intrinsic order.\n",
    "\n",
    "- ``Pandas`` Categorical dtype: Efficient memory representation and can be used for encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17900687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset:\n",
      "          City Weather  Severity  Accidents\n",
      "0     New York   Sunny         3        100\n",
      "1  Los Angeles   Rainy         2        150\n",
      "2     New York   Sunny         3        100\n",
      "3      Chicago  Cloudy         1         80\n",
      "4      Houston   Sunny         4         90\n",
      "5  Los Angeles   Rainy         2        150\n",
      "6       Boston   Rainy         3         60\n",
      "7       Boston   Sunny         3         60\n",
      "8      Chicago  Cloudy         1         80\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Synthetic dataset with categorical and duplicate rows\n",
    "data = {\n",
    "    'City': ['New York', 'Los Angeles', 'New York', 'Chicago', 'Houston', 'Los Angeles', 'Boston', 'Boston', 'Chicago'],\n",
    "    'Weather': ['Sunny', 'Rainy', 'Sunny', 'Cloudy', 'Sunny', 'Rainy', 'Rainy', 'Sunny', 'Cloudy'],\n",
    "    'Severity': [3, 2, 3, 1, 4, 2, 3, 3, 1],\n",
    "    'Accidents': [100, 150, 100, 80, 90, 150, 60, 60, 80]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original Dataset:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6075a0",
   "metadata": {},
   "source": [
    "### Remove Duplicates:\n",
    "Duplicates are repeated rows in the dataset that may bias analysis or models. Removing duplicates ensures data integrity and accuracy. Pandas `drop_duplicates()` method identifies and removes duplicate rows based on all or selected columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bab0be99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After removing duplicates:\n",
      "          City Weather  Severity  Accidents\n",
      "0     New York   Sunny         3        100\n",
      "1  Los Angeles   Rainy         2        150\n",
      "3      Chicago  Cloudy         1         80\n",
      "4      Houston   Sunny         4         90\n",
      "6       Boston   Rainy         3         60\n",
      "7       Boston   Sunny         3         60\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate rows\n",
    "df_no_duplicates = df.drop_duplicates()\n",
    "print(\"\\nAfter removing duplicates:\")\n",
    "print(df_no_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6586f171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label Encoded 'City' column:\n",
      "          City  City_Encoded\n",
      "0     New York             4\n",
      "1  Los Angeles             3\n",
      "3      Chicago             1\n",
      "4      Houston             2\n",
      "6       Boston             0\n",
      "7       Boston             0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win10\\AppData\\Local\\Temp\\ipykernel_18264\\397821232.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_duplicates['City_Encoded'] = df_no_duplicates['City'].astype('category').cat.codes\n"
     ]
    }
   ],
   "source": [
    "# Label Encoding with pandas category dtype\n",
    "df_no_duplicates['City_Encoded'] = df_no_duplicates['City'].astype('category').cat.codes\n",
    "print(\"\\nLabel Encoded 'City' column:\")\n",
    "print(df_no_duplicates[['City', 'City_Encoded']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8289ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "One-Hot Encoded 'Weather' column:\n",
      "          City  Severity  Accidents  City_Encoded  Weather_Cloudy  \\\n",
      "0     New York         3        100             4           False   \n",
      "1  Los Angeles         2        150             3           False   \n",
      "3      Chicago         1         80             1            True   \n",
      "4      Houston         4         90             2           False   \n",
      "6       Boston         3         60             0           False   \n",
      "\n",
      "   Weather_Rainy  Weather_Sunny  \n",
      "0          False           True  \n",
      "1           True          False  \n",
      "3          False          False  \n",
      "4          False           True  \n",
      "6           True          False  \n"
     ]
    }
   ],
   "source": [
    "# One-Hot Encoding using pandas get_dummies\n",
    "df_onehot = pd.get_dummies(df_no_duplicates, columns=['Weather'])\n",
    "print(\"\\nOne-Hot Encoded 'Weather' column:\")\n",
    "print(df_onehot.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170218fb",
   "metadata": {},
   "source": [
    "### Outliers Handling:\n",
    "Outliers are data points that deviate significantly from the majority distribution. They may be errors or rare events. \n",
    "\n",
    "Handling can be by:\n",
    "\n",
    "- Removal if they are errors or noise.\n",
    "\n",
    "- Capping or transformation to reduce skew.\n",
    "\n",
    "- Leaving as is if meaningful for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8e93b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected outliers:\n",
      "          City Weather  Severity  Accidents  City_Encoded\n",
      "1  Los Angeles   Rainy         2        150             3\n",
      "\n",
      "Dataset after removing outliers:\n",
      "       City Weather  Severity  Accidents  City_Encoded\n",
      "0  New York   Sunny         3        100             4\n",
      "3   Chicago  Cloudy         1         80             1\n",
      "4   Houston   Sunny         4         90             2\n",
      "6    Boston   Rainy         3         60             0\n",
      "7    Boston   Sunny         3         60             0\n",
      "\n",
      "Dataset after capping outliers:\n",
      "          City Weather  Severity  Accidents  City_Encoded\n",
      "0     New York   Sunny         3     100.00             4\n",
      "1  Los Angeles   Rainy         2     146.25             3\n",
      "3      Chicago  Cloudy         1      80.00             1\n",
      "4      Houston   Sunny         4      90.00             2\n",
      "6       Boston   Rainy         3      60.00             0\n",
      "7       Boston   Sunny         3      60.00             0\n"
     ]
    }
   ],
   "source": [
    "# Detecting and handling outliers in 'Accidents' column using IQR method:\n",
    "\n",
    "Q1 = df_no_duplicates['Accidents'].quantile(0.25)\n",
    "Q3 = df_no_duplicates['Accidents'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Identify outliers\n",
    "outliers = df_no_duplicates[(df_no_duplicates['Accidents'] < lower_bound) | (df_no_duplicates['Accidents'] > upper_bound)]\n",
    "print(\"\\nDetected outliers:\")\n",
    "print(outliers)\n",
    "\n",
    "# Option 1: Remove outliers\n",
    "df_no_outliers = df_no_duplicates[(df_no_duplicates['Accidents'] >= lower_bound) & (df_no_duplicates['Accidents'] <= upper_bound)]\n",
    "print(\"\\nDataset after removing outliers:\")\n",
    "print(df_no_outliers)\n",
    "\n",
    "# Option 2: Cap outliers (winsorizing)\n",
    "df_capped = df_no_duplicates.copy()\n",
    "df_capped['Accidents'] = np.where(df_capped['Accidents'] > upper_bound, upper_bound,\n",
    "                                  np.where(df_capped['Accidents'] < lower_bound, lower_bound, df_capped['Accidents']))\n",
    "print(\"\\nDataset after capping outliers:\")\n",
    "print(df_capped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef0d4af",
   "metadata": {},
   "source": [
    "### Task: \n",
    "- Visualize this outlier using boxplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0256ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
